import feedparser
import datetime
import re
from newspaper import Article
from googletrans import Translator
import nltk

# ìš”ì•½ ê¸°ëŠ¥ì„ ìœ„í•´ í•„ìš”í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ ì‹¤í–‰ë¨)
nltk.download('punkt')

def get_article_summary(url):
    try:
        article = Article(url, language='en') # ì¼ë‹¨ ì˜ì–´ë¡œ ì„¤ì • (êµ­ë‚´ë‰´ìŠ¤ë„ ì²˜ë¦¬ ê°€ëŠ¥)
        article.download()
        article.parse()
        article.nlp() # ìì—°ì–´ ì²˜ë¦¬ë¡œ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ
        return article.summary
    except:
        return ""

def clean_text(text):
    # ë²ˆì—­íˆ¬ ë° ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = text.replace(" .", ".").replace(" ,", ",")
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def fetch_and_format_news():
    translator = Translator()
    
    # 1. ê¶Œìœ„ ìˆëŠ” ì†ŒìŠ¤ ì„ ì • (ì‹¤ì œ ê¸°ì‚¬ ë§í¬ë¥¼ ì–»ê¸° ìœ„í•´ RSSë¥¼ 'ì£¼ì†Œë¡'ìœ¼ë¡œë§Œ í™œìš©)
    sources = {
        "ğŸ¤– ì¸ê³µì§€ëŠ¥ (AI)": "https://www.technologyreview.com/feed/", # MIT Tech Review
        "ğŸ›ï¸ ì •ì¹˜": "https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml", # NYT Politics
        "ğŸ¥ ì‚¬íšŒ": "https://www.yna.co.kr/rss/society.xml", # ì—°í•©ë‰´ìŠ¤ ì‚¬íšŒ
        "ğŸ“ êµìœ¡": "https://www.hangyo.com/rss/allArticle.xml" # í•œêµ­êµìœ¡ì‹ ë¬¸
    }
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    today_kr = now.strftime("%Yë…„ %mì›” %dì¼(%a)")
    
    # 2. í—¤ë” ì‘ì„± (ìš”ì²­í•˜ì‹  ë©˜íŠ¸ ê·¸ëŒ€ë¡œ)
    markdown = f"---\ndate: {today_str}\ntags: [ë‰´ìŠ¤, ìš”ì•½, ìë™í™”]\n---\n\n"
    markdown += f"# ğŸ“… {today_kr} ë¶„ì•¼ë³„ ìµœì‹  ë‰´ìŠ¤ ìš”ì•½\n\n"
    markdown += f"í˜„ì¬ ì‹œì ì„ ê¸°ì¤€ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥(AI), ì •ì¹˜, ì‚¬íšŒ, êµìœ¡ ë¶„ì•¼ì˜ ìµœì‹  ì£¼ìš” ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤. íŠ¹íˆ ê¸‰ë³€í•˜ëŠ” êµ­ì œ ì •ì„¸ì™€ ê¸°ìˆ  ë°œì „ì˜ íë¦„ì„ ì¤‘ì ì ìœ¼ë¡œ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.\n\n"
    
    first_title = "" # íŒŒì¼ëª…ìš© ë³€ìˆ˜

    for category, rss_url in sources.items():
        markdown += f"## {category}\n"
        
        try:
            feed = feedparser.parse(rss_url)
            # ë¶„ì•¼ë³„ ìƒìœ„ 2ê°œ ê¸°ì‚¬ë§Œ ì„ ì • (í€„ë¦¬í‹° ì§‘ì¤‘)
            for entry in feed.entries[:2]:
                
                # (1) ê¸°ì‚¬ ì›ë¬¸ ë‚´ìš© ì¶”ì¶œ
                original_summary = get_article_summary(entry.link)
                
                # ì¶”ì¶œ ì‹¤íŒ¨ì‹œ RSSì˜ ê¸°ë³¸ ì„¤ëª…ìœ¼ë¡œ ëŒ€ì²´
                if len(original_summary) < 50:
                    original_summary = entry.description if 'description' in entry else entry.title

                # (2) í•œêµ­ì–´ ë²ˆì—­ ë° ë‹¤ë“¬ê¸°
                title_kr = entry.title
                summary_kr = original_summary
                
                # í•´ì™¸ ì‚¬ì´íŠ¸(ì˜ì–´)ì¸ ê²½ìš° ë²ˆì—­ ì‹¤í–‰
                if "technologyreview" in rss_url or "nytimes" in rss_url:
                    try:
                        title_kr = translator.translate(entry.title, dest='ko').text
                        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ 400ìë§Œ ë²ˆì—­ (ì†ë„ ë° ê°€ë…ì„±)
                        summary_to_translate = original_summary[:1000] 
                        summary_kr = translator.translate(summary_to_translate, dest='ko').text
                    except:
                        pass
                
                # (3) í…ìŠ¤íŠ¸ ì •ì œ (HTML íƒœê·¸ ì‚­ì œ ë“±)
                title_kr = re.sub(r'[\[\]]', '', title_kr) # ëŒ€ê´„í˜¸ ì œê±°
                summary_kr = re.sub('<[^<]+?>', '', summary_kr) # HTML íƒœê·¸ ì œê±°
                summary_kr = clean_text(summary_kr)
                
                # ìš”ì•½ë¬¸ ê¸¸ì´ ì¡°ì ˆ (ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, ì„œìˆ í˜• ëŠë‚Œ)
                if len(summary_kr) > 250:
                    summary_kr = summary_kr[:250] + "..."
                
                # (4) ì¶œë ¥ í¬ë§· ì ìš© (ì œëª©: ë‚´ìš© ìŠ¤íƒ€ì¼)
                markdown += f"**{title_kr}**: {summary_kr}\n\n"

                # íŒŒì¼ëª… ìƒì„±ìš© (ì²« ê¸°ì‚¬ ì œëª©)
                if not first_title:
                    first_title = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', title_kr)[:15]

        except Exception as e:
            print(f"Error processing {category}: {e}")
            markdown += "ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"

    # 3. í‘¸í„° ì‘ì„±
    markdown += "---\n"
    markdown += "### ğŸ“‚ ê¸°ë¡ ì•ˆë‚´\n"
    markdown += f"ìœ„ ë‚´ìš©ì€ ì‚¬ìš©ìë‹˜ì˜ ìš”ì²­ì— ë”°ë¼ GitHub Actionsë¥¼ í†µí•´ ìë™ ìƒì„±ë˜ì–´ Obsidianìœ¼ë¡œ ë™ê¸°í™”ë©ë‹ˆë‹¤.\n"
    
    return f"{today_str}_{first_title}.md", markdown

if __name__ == "__main__":
    filename, content = fetch_and_format_news()
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"File created: {filename}")
