import datetime
import re
import requests
from bs4 import BeautifulSoup
import trafilatura

def get_clean_summary(url):
    try:
        # User-Agent ì„¤ì •ìœ¼ë¡œ ì°¨ë‹¨ ë°©ì§€
        downloaded = trafilatura.fetch_url(url)
        if downloaded is None: return ""

        text = trafilatura.extract(downloaded, include_comments=False)
        if not text or len(text) < 100: return ""

        # ë³¸ë¬¸ ì •ì œ
        text = text.replace('\n', ' ').strip()
        text = re.sub(r'\s+', ' ', text)

        sentences = text.split('. ')
        summary_sentences = []
        char_count = 0
        
        for sent in sentences:
            clean_sent = sent.strip()
            if len(clean_sent) < 20: continue
            if not clean_sent.endswith('.'): clean_sent += '.'
            
            summary_sentences.append(clean_sent)
            char_count += len(clean_sent)
            if char_count > 350: break
        
        return ' '.join(summary_sentences)
    except:
        return ""

def get_naver_section_links(sid1, sid2=None):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ë§í¬ë¥¼ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤.
    sid1: 105(IT/ê³¼í•™), 101(ê²½ì œ), 102(ì‚¬íšŒ)
    """
    links = []
    url = f"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1={sid1}"
    if sid2:
        url += f"&sid2={sid2}"
        
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"}
    
    try:
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë©”ì¸ í˜ì´ì§€ì˜ ê¸°ì‚¬ ë§í¬ íŒ¨í„´ ì¶”ì¶œ
        for a in soup.select('a[href*="article"]'):
            href = a['href']
            if href.startswith('https://n.news.naver.com/mnews/article/'):
                full_url = href.split('?')[0] # íŒŒë¼ë¯¸í„° ì œê±°
                if full_url not in links:
                    links.append(full_url)
            if len(links) >= 5: break # ë„‰ë„‰í•˜ê²Œ í›„ë³´êµ° 5ê°œ ìˆ˜ì§‘
    except Exception as e:
        print(f"Naver Scraping Error: {e}")
    
    return links

def fetch_news():
    # ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ ì½”ë“œ: 105(IT/AI), 101(ê²½ì œ), 102(ì‚¬íšŒ/êµìœ¡)
    sections = {
        "ğŸ¤– ì¸ê³µì§€ëŠ¥ (AI)": {"sid1": "105"},
        "ğŸ’° ê²½ì œ": {"sid1": "101"},
        "ğŸ“ êµìœ¡": {"sid1": "102", "sid2": "250"} # 250ì€ êµìœ¡ ì„¹ì…˜
    }
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    
    markdown = f"""---
date: {today_str}
last_update: {now.strftime("%Y-%m-%d %H:%M:%S")}
type: insight
topic: [ì¸ê³µì§€ëŠ¥, ê²½ì œ, êµìœ¡]
tags: [ë‰´ìŠ¤, ìš”ì•½, {today_str}]
---

# ğŸ“… {now.strftime('%Yë…„ %mì›” %dì¼(%a)')} í•µì‹¬ ë‰´ìŠ¤ ë¸Œë¦¬í•‘

"""
    
    for category, ids in sections.items():
        markdown += f"## {category}\n"
        print(f"Processing: {category}")
        
        links = get_naver_section_links(ids['sid1'], ids.get('sid2'))
        success_count = 0
        
        for link in links:
            if success_count >= 2: break
            
            summary = get_clean_summary(link)
            if not summary: continue
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ëŠ” trafilaturaê°€ ì œëª©ë„ ì˜ ê°€ì ¸ì˜µë‹ˆë‹¤.
            markdown += f"### ğŸ”— [ë‰´ìŠ¤ ê¸°ì‚¬ í™•ì¸í•˜ê¸°]({link})\n"
            markdown += f"> {summary}\n\n"
            success_count += 1
            
        if success_count == 0:
            markdown += "> ìµœì‹  ê¸°ì‚¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\n"

    markdown += "---\n### ğŸ“‚ ìë™í™” ê¸°ë¡ ì•ˆë‚´\n"
    filename = f"{today_str}_Daily_News_Briefing.md"
    return filename, markdown

if __name__ == "__main__":
    filename, content = fetch_news()
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
