import feedparser
import datetime
import re
import nltk
from newspaper import Article, Config

# ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

def get_clean_summary(url):
    """
    ê¸°ì‚¬ ë³¸ë¬¸ì„ ê¸ì–´ì™€ì„œ 'ì™„ë²½í•œ ë¬¸ì¥'ìœ¼ë¡œ êµ¬ì„±ëœ ìš”ì•½ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë§ ì¤„ì„í‘œ(...)ë¡œ ëë‚˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    # ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ë¸Œë¼ìš°ì € ìœ„ì¥ ì„¤ì •
    config = Config()
    config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'
    config.request_timeout = 10

    try:
        article = Article(url, config=config, language='ko')
        article.download()
        article.parse()
        
        # ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´(ìŠ¤í¬ë© ì‹¤íŒ¨ ë“±) ë¹ˆ ê°’ ë°˜í™˜ -> ëª©ë¡ì—ì„œ ì œì™¸ë¨
        if len(article.text) < 50:
            return ""

        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        text = article.text.strip()
        # ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì œê±°
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\s+', ' ', text)

        # ë§ˆì¹¨í‘œ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë‚˜ëˆ„ê¸° (ê°„ì´ ë¬¸ì¥ ë¶„ë¦¬)
        sentences = text.split('. ')
        
        # í•µì‹¬ 3~4ë¬¸ì¥ë§Œ ì¶”ì¶œ
        summary_sentences = []
        char_count = 0
        
        for sent in sentences:
            clean_sent = sent.strip()
            if not clean_sent: continue
            
            # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥(ê¸°ì ì´ë¦„ ë“±) ì œì™¸
            if len(clean_sent) < 10: continue
            
            # ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œ ë³µêµ¬
            if not clean_sent.endswith('.'):
                clean_sent += '.'
            
            summary_sentences.append(clean_sent)
            char_count += len(clean_sent)
            
            # ì•½ 300~400ì ì •ë„ ì±„ì›Œì§€ë©´ ì¤‘ë‹¨
            if char_count > 350:
                break
        
        # ë¬¸ì¥ë“¤ì„ ë‹¤ì‹œ í•©ì¹¨
        final_summary = ' '.join(summary_sentences)
        return final_summary

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ ê¸°ì‚¬ëŠ” ê±´ë„ˆëœ€
        return ""

def fetch_news():
    # 1. ìŠ¤í¬ë©ì´ í™•ì‹¤í•˜ê²Œ ì˜ ë˜ëŠ” 'ì§ì ‘ RSS' ì†ŒìŠ¤ ì„ ì •
    sources = {
        "ğŸ¤– ì¸ê³µì§€ëŠ¥ (AI)": "http://www.aitimes.com/rss/allArticle.xml", # AIíƒ€ì„ìŠ¤ (ì „ë¬¸ì§€)
        "ğŸ’° ê²½ì œ": "https://www.mk.co.kr/rss/30000001/", # ë§¤ì¼ê²½ì œ (ê²½ì œ)
        "ğŸ“ êµìœ¡": "https://rss.donga.com/education.php" # ë™ì•„ì¼ë³´ êµìœ¡ì„¹ì…˜ (ìŠ¤í¬ë© ì•ˆì •ì„± ë†’ìŒ)
    }
    
    now = datetime.datetime.now()
    today_str = now.strftime("%Y-%m-%d")
    update_time = now.strftime("%Y-%m-%d %H:%M:%S")
    
    # YAML Frontmatter
    markdown = f"""---
date: {today_str}
last_update: {update_time}
type: insight
topic: [ì¸ê³µì§€ëŠ¥, ê²½ì œ, êµìœ¡]
tags: [ë‰´ìŠ¤, ìš”ì•½, {today_str}]
source: [AIíƒ€ì„ìŠ¤, ë§¤ì¼ê²½ì œ, ë™ì•„ì¼ë³´]
---

# ğŸ“… {now.strftime('%Yë…„ %mì›” %dì¼(%a)')} í•µì‹¬ ë‰´ìŠ¤ ë¸Œë¦¬í•‘

"""
    
    first_title = "" 

    for category, rss_url in sources.items():
        markdown += f"## {category}\n"
        try:
            feed = feedparser.parse(rss_url)
            
            # ë¶„ì•¼ë³„ ì„±ê³µí•œ ê¸°ì‚¬ 2ê°œë§Œ ìˆ˜ì§‘
            success_count = 0
            
            for entry in feed.entries:
                if success_count >= 2: break
                
                # ë³¸ë¬¸ ìŠ¤í¬ë© ì‹œë„
                summary = get_clean_summary(entry.link)
                
                # ìŠ¤í¬ë© ì‹¤íŒ¨í–ˆê±°ë‚˜ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê³¼ê°íˆ ê±´ë„ˆëœ€ (ë§ì¤„ì„í‘œ ë°©ì§€)
                if not summary:
                    continue
                
                markdown += f"### ğŸ”— [{entry.title}]({entry.link})\n"
                markdown += f"> {summary}\n\n"
                
                # íŒŒì¼ëª…ìš© ì œëª© ì¶”ì¶œ
                if not first_title:
                    clean_title = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', entry.title).strip()
                    first_title = clean_title.replace(" ", "_")[:15]
                
                success_count += 1
                
        except Exception as e:
            print(f"Error in {category}: {e}")

    markdown += "---\n"
    markdown += f"### ğŸ“‚ ìë™í™” ê¸°ë¡ ì•ˆë‚´\n"
    markdown += f"ìµœì¢… ì—…ë°ì´íŠ¸ ì‹œê°: **{update_time}**\n"
    
    filename = f"{today_str}_{first_title}.md"
    return filename, markdown

if __name__ == "__main__":
    filename, content = fetch_news()
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"Created: {filename}")
